{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNd053EGgOAxPx+KqM8gU1T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akage1234/nn-zero-to-hero/blob/main/NLP/Transformer/GPT/gpt_exp_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning the concepts"
      ],
      "metadata": {
        "id": "zhBhrUl0Tl5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-hBrysQ3p3m",
        "outputId": "bb29660a-295e-4ea1-b639-646e9a3867b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-24 20:10:44--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘shakespeare.txt’\n",
            "\n",
            "\rshakespeare.txt       0%[                    ]       0  --.-KB/s               \rshakespeare.txt     100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-10-24 20:10:44 (50.1 MB/s) - ‘shakespeare.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O shakespeare.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "with open(\"shakespeare.txt\", 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "CPx-paEa8DdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "089UH_As8tP8",
        "outputId": "769a7d06-7ecc-461f-cfac-8fa29101ee0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGNHAh038NI6",
        "outputId": "caabff12-15f9-4e39-f99e-2bcd17dfacd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "s = encode('Hello')\n",
        "print(s)\n",
        "print(decode(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-A0Ywqp892r",
        "outputId": "120be5b2-8859-4b4e-b7d1-3d697f21782b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53]\n",
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFsBXNm7-GfR",
        "outputId": "5ac3837a-a76e-41c0-eb03-0f14a7073a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "UrcBp0w4-myH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print(\"Inputs:\\n\",xb.shape)\n",
        "print(xb)\n",
        "print(\"Outputs:\\n\",yb.shape)\n",
        "print(yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dyLv5aJ_nDt",
        "outputId": "b2d3fa3b-4325-42ca-fdaf-c13cf0b8ebe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "Outputs:\n",
            " torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context} output is :{target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H7ER-yIBWpm",
        "outputId": "2d07ca7f-2114-4e44-8222-cc4e670e3d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([24]) output is :43\n",
            "when input is tensor([24, 43]) output is :58\n",
            "when input is tensor([24, 43, 58]) output is :5\n",
            "when input is tensor([24, 43, 58,  5]) output is :57\n",
            "when input is tensor([24, 43, 58,  5, 57]) output is :1\n",
            "when input is tensor([24, 43, 58,  5, 57,  1]) output is :46\n",
            "when input is tensor([24, 43, 58,  5, 57,  1, 46]) output is :43\n",
            "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) output is :39\n",
            "when input is tensor([44]) output is :53\n",
            "when input is tensor([44, 53]) output is :56\n",
            "when input is tensor([44, 53, 56]) output is :1\n",
            "when input is tensor([44, 53, 56,  1]) output is :58\n",
            "when input is tensor([44, 53, 56,  1, 58]) output is :46\n",
            "when input is tensor([44, 53, 56,  1, 58, 46]) output is :39\n",
            "when input is tensor([44, 53, 56,  1, 58, 46, 39]) output is :58\n",
            "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) output is :1\n",
            "when input is tensor([52]) output is :58\n",
            "when input is tensor([52, 58]) output is :1\n",
            "when input is tensor([52, 58,  1]) output is :58\n",
            "when input is tensor([52, 58,  1, 58]) output is :46\n",
            "when input is tensor([52, 58,  1, 58, 46]) output is :39\n",
            "when input is tensor([52, 58,  1, 58, 46, 39]) output is :58\n",
            "when input is tensor([52, 58,  1, 58, 46, 39, 58]) output is :1\n",
            "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) output is :46\n",
            "when input is tensor([25]) output is :17\n",
            "when input is tensor([25, 17]) output is :27\n",
            "when input is tensor([25, 17, 27]) output is :10\n",
            "when input is tensor([25, 17, 27, 10]) output is :0\n",
            "when input is tensor([25, 17, 27, 10,  0]) output is :21\n",
            "when input is tensor([25, 17, 27, 10,  0, 21]) output is :1\n",
            "when input is tensor([25, 17, 27, 10,  0, 21,  1]) output is :54\n",
            "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) output is :39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx) # B, T, C\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self(idx)\n",
        "            logits = logits[:, -1, :] # becomes B, C\n",
        "            probs = F.softmax(logits, dim = -1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "DgjZk_VOBtEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = BigramModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "idx = m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)\n",
        "print(decode(idx[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLr-qxNXAP-y",
        "outputId": "951837a9-723e-4d8f-c0a2-c21f20e65399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
            "wnYWmnxKWWev-tDqXErVKLgJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1EuqhuCBAae-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOkHNk5DG2k",
        "outputId": "74177691-6602-41a8-9493-3b74556121c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.382369041442871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)\n",
        "print(decode(idx[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pIQoKPaE6R9",
        "outputId": "eb36f473-b032-4ed6-f88a-b7d0135450ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lso br. ave aviasurf my, yxMPZI ivee iuedrd whar ksth y h bora s be hese, woweee; the! KI 'de, ulseecherd d o blllando;LUCEO, oraingofof win!\n",
            "RIfans picspeserer hee tha,\n",
            "TOFonk? me ain ckntoty ded. bo'llll st ta d:\n",
            "ELIS me hurf lal y, ma dus pe athouo\n",
            "BEY:! Indy; by s afreanoo adicererupa anse tecorro llaus a!\n",
            "OLeneerithesinthengove fal amas trr\n",
            "TI ar I t, mes, n IUSt my w, fredeeyove\n",
            "THek' merer, dd\n",
            "We ntem lud engitheso; cer ize helorowaginte the?\n",
            "Thak orblyoruldvicee chot, p,\n",
            "Bealivolde Th li\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The mathematical trick and self attention"
      ],
      "metadata": {
        "id": "kTgLWyNGIXPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XVE0cUzFx5h",
        "outputId": "f5173235-b5d3-4992-9e8b-b08725f3ac1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b, :t+1]\n",
        "        xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "H3iprq8ZIlig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "a = a/ torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print(a)\n",
        "print('-'*50)\n",
        "print(b)\n",
        "print('-'*50)\n",
        "print(c)\n",
        "print('-'*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46HLP58olw21",
        "outputId": "c946f506-7eb4-4c46-81ab-a287daddc5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--------------------------------------------------\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--------------------------------------------------\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True) # all the rows sum upto 1\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)\n",
        "print(xbow[0])\n",
        "print(xbow2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyZr8fYdR_Nr",
        "outputId": "e147a991-5333-4c40-cb4b-0bb8ac067ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# different version\n",
        "from torch.nn import functional as F\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81ecW7mSVvm",
        "outputId": "75ea1928-818e-43c9-9058-678e056c7092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self-attention\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "out.shape"
      ],
      "metadata": {
        "id": "m6M6zqjPUa4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fully Finished code & output"
      ],
      "metadata": {
        "id": "GoeI8fyY12u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "\n",
        "with open(\"shakespeare.txt\", 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            xb, yb = get_batch(split)\n",
        "            logits, loss = model(xb, yb)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "## Attention Head\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "# Multi head attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "# Feed Forward\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4* n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_heads\n",
        "        self.sa_heads = MultiHeadAttention(n_heads, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x + self.sa_heads(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "## Bigram Language Model\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.positional_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
        "        pos_emb = self.positional_embedding_table(torch.arange(T, device=device)) # (T, n_embd)\n",
        "        x = tok_emb + pos_emb # (B, T, C)\n",
        "        x = self.blocks(x)\n",
        "        logits = self.lm_head(x) # (B, T, Vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :] # becomes B, C\n",
        "            probs = F.softmax(logits, dim = -1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = GPTModel()\n",
        "m = m.to(device)\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in tqdm(range(max_iters), desc=\"Training\"):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"\\n  step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABOHQwWc14ue",
        "outputId": "57228c53-b456-4942-96bc-cc9ed33feaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1115394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/5000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 0: train loss 3.0286, val loss 3.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  10%|█         | 501/5000 [06:46<28:50:08, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 500: train loss 3.0320, val loss 3.0681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  20%|██        | 1001/5000 [12:27<25:43:08, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 1000: train loss 3.0286, val loss 3.0676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  30%|███       | 1501/5000 [18:06<22:18:21, 22.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 1500: train loss 3.0289, val loss 3.0700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  40%|████      | 2001/5000 [23:46<19:09:16, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 2000: train loss 3.0312, val loss 3.0676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  50%|█████     | 2501/5000 [29:24<15:56:34, 22.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 2500: train loss 3.0327, val loss 3.0690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  60%|██████    | 3001/5000 [35:03<12:43:28, 22.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 3000: train loss 3.0305, val loss 3.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  70%|███████   | 3501/5000 [40:42<9:32:18, 22.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 3500: train loss 3.0303, val loss 3.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  80%|████████  | 4000/5000 [45:05<08:48,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 4000: train loss 3.0319, val loss 3.0680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  90%|█████████ | 4501/5000 [51:58<3:11:11, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  step 4500: train loss 3.0286, val loss 3.0686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5000/5000 [56:21<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Touch the length of our proclaims cell'st off,\n",
            "And confession out of exquision.\n",
            "\n",
            "ANGELO:\n",
            "Here can yes must report\n",
            "Off the hands voices and regive; and not extremise,\n",
            "There tus striught make the lose: be next not\n",
            "Till I feel what was fain deputy.\n",
            "\n",
            "MARIANA:\n",
            "Let not on then charactes him and climbs.\n",
            "To sliep then and poperticy'd and that\n",
            "For wolving foot, bid their heads proclaiming\n",
            "Were times and the changer first have\n",
            "Till mine enemies or spurch'd\n",
            "Than beautish'd them. He comes, fearful friends!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGm-JaDfNrmP",
        "outputId": "81c01095-da30-4b8a-a188-7da83a0f9a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "We look too? think we this man\n",
            "To the Earwise hence in being farewell\n",
            "Oxenusuances. Shall I have so you to his honour!\n",
            "\n",
            "Patience:\n",
            "This true?\n",
            "\n",
            "CARDITAL:\n",
            "Nay, thou hast saint on thy conqueror is,\n",
            "The courtesy thought to set the Capules.\n",
            "\n",
            "BRUTUS:\n",
            "Welcomment followned to obather and Christ's Sly\n",
            "To that any martless to Good smalled thou know\n",
            "And bear the wiser ruther. What couran do I can\n",
            "thee's neithern?\n",
            "\n",
            "First Senator:\n",
            "My lord, durst banish'd in Tirture. O Thursdom!\n",
            "\n",
            "CORIOLANUS:\n",
            "First he, my deeds, cousin, I have;\n",
            "And deal as Working o'er--O happy that setige,\n",
            "Meaning to me by a word;\n",
            "Or by with his honours and steeps them we\n",
            "To Pound of Such high dry Gaunt a rashness!\n",
            "That feel he will advenge\n",
            "The ungerators to long; for whose boths doot\n",
            "Which intended an oath ignoble pridage,\n",
            "Whilst he towards my consuls than a kder\n",
            "Of carversion Clifford and\n",
            "More Earcum's little battle begther,\n",
            "With fox revenger, war, but look'd the creature,\n",
            "And venom upon these strong of cheeks in sight,\n",
            "Hath grace that e the seal thriving renown:\n",
            "But his suspecture and directiture him,\n",
            "That old true and discroop'd trience cares agire\n",
            "So leave as an as his deed; and this cast\n",
            "To warCh is out all groan:\n",
            "As therefore than any inforcess.\n",
            "\n",
            "RUTCHESS XIO:\n",
            "Not be mine.\n",
            "\n",
            "STANLY:\n",
            "ANANGHUMBELLA:\n",
            "Marry, my sorrow: what say th !\n",
            "\n",
            "ANGELO:\n",
            "My liege, there wanders. Clarence is good I go.\n",
            "\n",
            "ANGELO:\n",
            "Why do I sent them it there.\n",
            "\n",
            "Third Gent BOlbarn:\n",
            "He scoldiers not The gave pardon that,\n",
            "hath yield all the blood fathers of thine.\n",
            "\n",
            "LUCIO:\n",
            "\n",
            "Pray you, Lord!\n",
            "\n",
            "ANGELO:\n",
            "Gring Mextimes and not Masher's tender stripts:\n",
            "therefore Gon yea, post that, Braughtista;\n",
            "to the world that insafe cries their\n",
            "of yon each of proceers greatness.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Sir! this is was a gentle piteous of head,\n",
            "and wall runn'd the wahonounce. Came your Marcius;\n",
            "and then hughth by yours and them\n",
            "And Ayarel bshoke--\n",
            "\n",
            "wound IUS:\n",
            "Anow them Duke?\n",
            "\n",
            "Provost:\n",
            "No, I will not they. 'True.\n",
            "\n",
            "BRUTUS:\n",
            "Farewell; and we have not adone with your mothers\n",
            "Found the earth's verbooks beholding tore\n",
            "It delions to success anon\n",
            "About a sleepy\n",
            "To any poor to a common pint anoints: do they am\n",
            "I do leg.\n",
            "\n",
            "DORCAS:\n",
            "A bethink to presure of wine inecessity.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Held hence is God will not parlislelingbrant.\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "But I, let him be at traitise,\n",
            "Not stay and will their selves of your death.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "O, that you say what think you remain his, sirly\n",
            "Lord Taphio to hear France and fivil his unkindness,\n",
            "And Warwick the that though Ned; so quench the Earl heir\n",
            "Inteed of yon perpoof: prove with his\n",
            "Under his face religion: dost thou meet already\n",
            "To Georance for a headly sent to a right traitor sound\n",
            "Than and talk supporant from her desire?\n",
            "\n",
            "Gaoler:\n",
            "Grant yiel, these sows.\n",
            "\n",
            "Clown:\n",
            "It is God leave your hate shall an hief.\n",
            "\n",
            "\n",
            "KING RICHARD II:\n",
            "Many for worthymung times to joy\n",
            "By crave torcy hand, I am thee grown polixenes\n",
            "With true lord the mind, tomach'd him ow words\n",
            "May carry have wring these from the things Iysabelle;\n",
            "Are notwixt a room toward husband king!\n",
            "Our brace and Sir careful Lancasters,\n",
            "Whereuping such sway sell on heart\n",
            "Is pockersion of shatten himll:\n",
            "I meet him as caused mothering,\n",
            "To whose friend and none him that Tebbory.\n",
            "\n",
            "CORIOLANUS:\n",
            "Ay, if hope to hence speak to himself\n",
            "I have thence to the law King Henry hath and\n",
            "Arish'd invatorce cry with impoundship of marrel:\n",
            "Hath chaged 'God to soon are apass\n",
            "Lord Bishoke and vain. Say, come peace his hanger\n",
            "than afe--counse, deserve; and tooth hail,\n",
            "Hath always feel sure by coriest as through,\n",
            "And they jot to exchange them on your hearts:\n",
            "In apperally beyard, I wondow. Ah rescence\n",
            "And all their feadly and robsed youth\n",
            "Will be solently with him her; and which but show hatch\n",
            "I, 'gainst it with me more resolution: what\n",
            "Harquaken waters and with himself a lord persuaded,\n",
            "Whilist she pluxshion to their from to your\n",
            "In onsuper of work not what brindeth him.\n",
            "\n",
            "MARCIUS:\n",
            "More gentle common that never word you are\n",
            "And by your my pooting nurse\n",
            "Shall here incany out:\n",
            "For in what person honour faces pherity:\n",
            "Though wit thise days uncle, must not on the\n",
            "Supper and tall goods that which you will be well.\n",
            "\n",
            "Messenger:\n",
            "Young Caesa, and with blood men friends your trawl.\n",
            "\n",
            "A pardons old Montaguens, chair, who capled\n",
            "bawlamen? Nay, be revenged our Jove\n",
            "to her to-friend, so ravident, or lexitious\n",
            "hones a widings but as preasing days.\n",
            "O stand leads!\n",
            "To make thy merit impicianness shats\n",
            "To help my Lord Henry May make woman:\n",
            "And, determise in heig!\n",
            "\n",
            "WARWICK:\n",
            "Where on all youngest I requise\n",
            "To Henry.\n",
            "\n",
            "YORK:\n",
            "What, Clarence! blass the chamberland mets,\n",
            "And men the rival press'd his strongth of fortune?\n",
            "Where do you had madest the created speans,\n",
            "To bend report and comperfession;\n",
            "But partise repairing in our sighs,\n",
            "Enjoile wot glad where I be reward\n",
            "The clouds in your eyesign's places, fortune\n",
            "Perfice may be sed.\n",
            "\n",
            "CLARENCE:\n",
            "I tell you go on, so\n",
            "I will my wedge nest seize a town again\n",
            "This such einter\n",
            "To the bony towards; and, therefore I say the master:\n",
            "For inform stoop and crackily\n",
            "Mothught employs? What will I had her rain\n",
            "To lie own to deceath woo! Nay, that be done!\n",
            "\n",
            "MAMILIANA:\n",
            "Their comes thyself my defence 'loyance.\n",
            "\n",
            "GLOUCESTER:\n",
            "Now not I say her names tongue, but grant hold:\n",
            "But this day in me, where hath Benvirture,\n",
            "Brought to smile Plantagentagenet, ago;\n",
            "Whiling Bapentiphy, regrection, hangmen\n",
            "With lose and reviventure stroings,\n",
            "Yet life, men, if hearing be in so honour.\n",
            "Aimself that do solice\n",
            "That, I should by a vaultime of Brecope and so\n",
            "Spirite or circumstance hope of a sacre!\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Or for Isabel?\n",
            "\n",
            "QUEEN MARGARIA:\n",
            "Peace, post day in thy badies,\n",
            "To bare my son Guarent to shroud Angelo,\n",
            "My should count that I would canst herhief:\n",
            "Worse to wain his batter?\n",
            "\n",
            "ROMEO:\n",
            "Stay, Romeo? these child Nor Romeoner next thee? though not\n",
            "Marchy upon his he strength, and entreat's sweet\n",
            "Prepetuance parting out hars, Gabering as Exthrush.\n",
            "\n",
            "WAY:\n",
            "O God! O What!\n",
            "\n",
            "\n",
            "SREET:\n",
            "O my helping with wind, Warwick, when a wits,\n",
            "Though we are here and so means\n",
            "To be but my free and talk.\n",
            "\n",
            "Servant:\n",
            "Here consents are this Pomfret Delbowit;\n",
            "Is Shat forth Cliffords the tear lords of Marcius?\n",
            "\n",
            "HASTINGS:\n",
            "Remember! I say I, craid, my lord;\n",
            "There somethough I medies go: and me with away:\n",
            "Thear fair any faction stands my heart;\n",
            "With all world such grace and loveries\n",
            "Cound raison of his longs joys:\n",
            "That Clifford homina Buckingham are and Shore,\n",
            "Your sight-wearing\n",
            "That looks has mine a doth spirit had it,\n",
            "And lean out leaden the morning claisf:\n",
            "I the chastiss that thou of this star:\n",
            "Which this a merriles to speak,\n",
            "Whose breast grant tossings noblement\n",
            "The honour's death, should grant deparage\n",
            "Thy gracious commandmend, and the weathswired:\n",
            "When we that conduct of olls thy intentigannor\n",
            "Of Bregan it army.\n",
            "Mayor Harry the Duke off North,\n",
            "'Saint Green upon Henry Beaum,\n",
            "And but what lacks did sorrow at hour's blood,\n",
            "My sineam Minegnely shall staught instrume hade him.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I wish me speak a fight of foot\n",
            "By tright. And therefore I melute repair to Gauntle\n",
            "To truship th aught queen? Camillant for the\n",
            "sick of sights born.\n",
            "\n",
            "MARIANA:\n",
            "No, noble.\n",
            "\n",
            "CAMUS:\n",
            "I stoop draw not yesteed slore: how nay, to desire.\n",
            "\n",
            "Yield your known the richance balms, wedoundard:\n",
            "Where ye shall be, burn marry not is time\n",
            "So gentle to one inours.\n",
            "\n",
            "BENVOLIO:\n",
            "Grand you!\n",
            "\n",
            "BENVOLIO:\n",
            "And yet not in this that honour made grief\n",
            "Denting by my least grands that kings be ruin.\n",
            "\n",
            "ROMEO:\n",
            "Nay, should you know!\n",
            "She shall have lelded she.\n",
            "\n",
            "CAMILLO:\n",
            "I gracious Pray Lord Northumberland,--\n",
            "\n",
            "ROMEO:\n",
            "Ca Tcle-villain and out, Lancaster;\n",
            "Which should she knows\n",
            "Is like, sparing, and being\n",
            "From them restraining; and air, those weary.\n",
            "\n",
            "MERCUTIO:\n",
            "Swicing one and that has ensires his brancoker\n",
            "As Herver silenrer now this crown fromes folks proonder:\n",
            "Now Libert they are eleven\n",
            "May both turn traitor, for ant child,\n",
            "Iss fills too large, and see how them corn:\n",
            "Their persocunes and creature to name of curse\n",
            "When hen did ill I scaring overseign. Bushok,\n",
            "The mery proceed playful doth himself.\n",
            "\n",
            "LUCIO:\n",
            "I have been a pleasure many Clarence straight.\n",
            "\n",
            "JORNIZET:\n",
            "O boy! a for such dispantings traitor woes,\n",
            "Thereforess to kiss cages from Floughband,\n",
            "And thet trainly be my heart's death for their\n",
            "At they collaries.\n",
            "\n",
            "MARCIUS:\n",
            "One besides of thy mean hath got as they born:\n",
            "Petire: this as in his out and hide a\n",
            "shepherd's reved, my best consul woman's brace\n",
            "prosperation hath a saucy sent both doom\n",
            "Than out my knee. Nomen he's the marksmony that they\n",
            "Then marriage.\n",
            "\n",
            "All:\n",
            "To myself partnight here strence.\n",
            "\n",
            "ROMEO:\n",
            "No:\n",
            "Madam! I shall be witness?\n",
            "\n",
            "CORIOLANUS:\n",
            "Hail, you have prisonounce, lord, at death!\n",
            "\n",
            "MENENIO:\n",
            "You changed on the strongest sovereignt love,\n",
            "For than forsake you all to your gungle.\n",
            "\n",
            "MENENIO:\n",
            "If Queen that chieves do you th caught thou heir\n",
            "And though this valumation. Thore is younger\n",
            "From to prise the noison: brother, nothing.\n",
            "There, take you by my ling; for I can fray thee.\n",
            "Your can rememped grace.\n",
            "\n",
            "MARCISTIUS:\n",
            "Pray the duke of your honour,\n",
            "Horse thy consulse, I say in\n",
            "The child-shame bent so repaised\n",
            "Wherein as long: as dies such so dare\n",
            "To tell my acceptuntions in my royal knavers\n",
            "Can legg dewly in this numbasing sound,\n",
            "Stiliging in execution joints wifes\n",
            "Leieve not to reign and thy relegiance.\n",
            "O, by the good Bapenso: had him strong,\n",
            "To strugge the heir ture denied meet,\n",
            "Block no nay: but, as didst take on him like\n",
            "Disime my hand: let me while left maje a come.\n",
            "He cause of ourselves no old confessions,\n",
            "To say 'O indish the rejoices that cause things these\n",
            "Of Montaguen belown;\n",
            "For to dry so troth two office to our house,\n",
            "And my wife, rouse, tell me her for tend,\n",
            "By proved both to one despite with loss. How\n",
            "Nay, shall you be how in warm with tears one;\n",
            "For which that he woo would fall seek to hers,\n",
            "For any wrewds down! And that was specious!\n",
            "Trull, thou wash in the generation,\n",
            "And very helpily of report again\n",
            "To Bluntagot. Where was son, I warranted with\n",
            "She's self: Rome another than a sense to other\n",
            "Our general-pornicance. I have done remedy,\n",
            "Pleady, in all \n"
          ]
        }
      ]
    }
  ]
}